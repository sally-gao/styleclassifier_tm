{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import itertools\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(path, replace_dict, min_length=10):\n",
    "    \"\"\"\n",
    "    Removes source-specific artifacts from documents.\n",
    "    \n",
    "    :param path: filepath containing JSON files for each document\n",
    "    :param replace_dict: dictionary containing regex matching strings and strings to replace them with\n",
    "    :param min_length: minimum document length\n",
    "    \n",
    "    :returns: list of strings, each containing document content\n",
    "    \"\"\"\n",
    "    \n",
    "    docs = []\n",
    "    #files = os.listdir(path)\n",
    "    json_files = [pos_json for pos_json in os.listdir(path) if pos_json.endswith('.json')]\n",
    "\n",
    "    for file in json_files:\n",
    "        #file = '\\\\' + file\n",
    "        content = json.load(open(path + file))['content']\n",
    "        \n",
    "        # replace regex strings\n",
    "        for key, value in replace_dict.items():\n",
    "            content = re.sub(key, value, content)\n",
    "        \n",
    "        # remove small documents\n",
    "        if len(content) >= min_length:\n",
    "            docs.append(content)\n",
    "        \n",
    "    return(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Economist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "economist_path = 'data_updated/economist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "economist_dict = {}\n",
    "\n",
    "# artifacts on accented letters\n",
    "economist_dict['AaAaAeA '] = 'i'\n",
    "economist_dict['AaAaAeAo'] = 'c'\n",
    "economist_dict['AaAaAeAc'] = 'a'\n",
    "economist_dict['AaAaAeA~'] = 'n'\n",
    "economist_dict['AaAaAeA@|AaAaAeA\\?|AaAaAeA{|AaAaAe'] = 'e'\n",
    "\n",
    "\n",
    "\n",
    "# numbers\n",
    "economist_dict['([\\d]+)([.,]?)([\\d]+)'] = 'NUM'\n",
    "\n",
    "\n",
    "# Go online artifacts\n",
    "# end paragraph without punctuation (probably headers or titles)\n",
    "economist_dict['<p>Go online ([^<]*)</p>|<p>([^<]*)([^.?!\"]){1}</p>'] = ''\n",
    "\n",
    "# end of paragraph tags\n",
    "economist_dict['</p>'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "economist_docs = process_corpus(economist_path, economist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104\n"
     ]
    }
   ],
   "source": [
    "print(len(economist_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "economist_paragraphs = []\n",
    "for doc in economist_docs:\n",
    "    economist_paragraphs += doc.strip().split('<p>')\n",
    "    \n",
    "economist_paragraphs = [doc.strip() for doc in economist_paragraphs if len(doc) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11198"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(economist_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wired_path = 'data_updated/wired/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wired_dict = {}\n",
    "\n",
    "# numbers\n",
    "wired_dict['([\\d]+)([.,]?)([\\d]+)'] = 'NUM'\n",
    "\n",
    "# end paragraph without punctuation (probably headers or titles)\n",
    "# author/subject descriptions at end of article\n",
    "# paragraph symbols\n",
    "wired_dict['<p>([^<]*)([^.?!\"]){1}</p>|<p>([^<]*)([A-Z]+) \\(@(.*)|Â¶'] = ''\n",
    "\n",
    "#email addresses\n",
    "wired_dict['[\\w\\.-]+@[\\w\\.-]+']=''\n",
    "\n",
    "# end of paragraph tags\n",
    "wired_dict['</p>'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wired_docs = process_corpus(wired_path, wired_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296\n"
     ]
    }
   ],
   "source": [
    "print(len(wired_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wired_paragraphs = []\n",
    "\n",
    "for doc in wired_docs:\n",
    "    wired_paragraphs += doc.strip().split('<p>')\n",
    "    \n",
    "wired_paragraphs = [doc.strip() for doc in wired_paragraphs if len(doc) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17142"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wired_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Yorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newyorker_path = 'data_updated/newyorker/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newyorker_dict = {}\n",
    "\n",
    "# artifacts on accented letters\n",
    "newyorker_dict['AaAaAeA '] = 'i'\n",
    "newyorker_dict['AaAaAeAo'] = 'c'\n",
    "newyorker_dict['AaAaAeAc'] = 'a'\n",
    "newyorker_dict['AaAaAeA~'] = 'n'\n",
    "newyorker_dict['AaAaAeA@|AaAaAeA\\?|AaAaAeA{|AaAaAe'] = 'e'\n",
    "\n",
    "# numbers\n",
    "newyorker_dict['([\\d]+)([.,]?)([\\d]+)'] = 'NUM'\n",
    "\n",
    "# end paragraph without punctuation (probably headers or titles)\n",
    "# bylines\n",
    "newyorker_dict['<p>([^<]*)([^.?!\"]){1}</p>|<p>Byline([^<]*)</p>'] = ''\n",
    "\n",
    "# end of paragraph tags\n",
    "newyorker_dict['</p>'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "newyorker_docs = process_corpus(newyorker_path, newyorker_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "807\n"
     ]
    }
   ],
   "source": [
    "print(len(newyorker_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "newyorker_paragraphs = []\n",
    "for doc in newyorker_docs:\n",
    "    newyorker_paragraphs += doc.strip().split('<p>')\n",
    "    \n",
    "newyorker_paragraphs = [doc.strip() for doc in newyorker_paragraphs if len(doc) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19030"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newyorker_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_path = 'data_updated/ew/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_dict = {}\n",
    "\n",
    "# artifacts on accented letters\n",
    "ew_dict['AaAaAeA '] = 'i'\n",
    "ew_dict['AaAaAeAo'] = 'c'\n",
    "ew_dict['AaAaAeAc'] = 'a'\n",
    "ew_dict['AaAaAeA~'] = 'n'\n",
    "ew_dict['AaAaAeA@|AaAaAeA\\?|AaAaAeA{|AaAaAe'] = 'e'\n",
    "\n",
    "# numbers\n",
    "ew_dict['([\\d]+)([.,]?)([\\d]+)'] = 'NUM'\n",
    "\n",
    "#email addresses\n",
    "ew_dict['[\\w\\.-]+@[\\w\\.-]+']=''\n",
    "\n",
    "# Go online artifacts\n",
    "# end paragraph without punctuation (probably headers or titles)\n",
    "#ew_dict['<p>Go online ([^<]*)</p>|<p>([^<]*)([^.?!+\"]){1}</p>'] = ''\n",
    "\n",
    "#bullet points\n",
    "ew_dict['\\xc2\\xb7']=''\n",
    "\n",
    "# end of paragraph tags\n",
    "ew_dict['</p>'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_docs = process_corpus(ew_path, ew_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2190\n"
     ]
    }
   ],
   "source": [
    "print(len(ew_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_paragraphs = []\n",
    "\n",
    "for doc in ew_docs:\n",
    "    ew_paragraphs += doc.strip().split('<p>')\n",
    "    \n",
    "ew_paragraphs = [doc.strip() for doc in ew_paragraphs if len(doc) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ratings(graf):\n",
    "    \n",
    "    \"\"\"Removes ratings such as \"B+\", \"A\", \"C-\" from the end of a paragraph.\"\"\"\n",
    "    \n",
    "    # Check if the last character in the last word is a sentence-ending character ('.', '!' and so on)\n",
    "    if not any(x == graf.split()[-1][-1] for x in ['.', '!', '?', '\\\"', ')', 'â', 'â¦']):\n",
    "        \n",
    "        # If not, return paragraph with the last word removed\n",
    "        return graf[0:-len(graf.split()[-1])].strip()\n",
    "    \n",
    "    else:\n",
    "        return graf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_paragraphs = [remove_ratings(p) for p in ew_paragraphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17536\n"
     ]
    }
   ],
   "source": [
    "print(len(ew_paragraphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = economist_paragraphs + wired_paragraphs + newyorker_paragraphs+ew_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = list(itertools.repeat('economist', len(economist_paragraphs)))\n",
    "sources += list(itertools.repeat('wired', len(wired_paragraphs)))\n",
    "sources += list(itertools.repeat('newyorker', len(newyorker_paragraphs)))\n",
    "sources +=list(itertools.repeat('ew',len(ew_paragraphs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'content':paragraphs, 'source':sources}\n",
    "final_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64906"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOWN the Euphrates river, halfway between Deir...</td>\n",
       "      <td>economist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Never have America and its allies had such a h...</td>\n",
       "      <td>economist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But like their Parthian forebears, Iran and it...</td>\n",
       "      <td>economist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iran's gains are even more striking elsewhere....</td>\n",
       "      <td>economist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Farther south, America's hopes of stemming Ira...</td>\n",
       "      <td>economist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content     source\n",
       "0  DOWN the Euphrates river, halfway between Deir...  economist\n",
       "1  Never have America and its allies had such a h...  economist\n",
       "2  But like their Parthian forebears, Iran and it...  economist\n",
       "3  Iran's gains are even more striking elsewhere....  economist\n",
       "4  Farther south, America's hopes of stemming Ira...  economist"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv('pre_pre_processed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeHTMLTags(x):\n",
    "    content = re.sub(\"(?i)<\\/?\\w+((\\s+\\w+(\\s*=\\s*(?:\\\".*?\\\"|'.*?'|[^'\\\">\\s]+))?)+\\s*|\\s*)\\/?>\", '', x)\n",
    "    #content1 = re.sub(\"\\\\b\\\\x94\\\\b\", ' ', content)\n",
    "    \n",
    "    return(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Content_Preprocessed']=final_df['content'].apply(lambda x:removeHTMLTags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    DOWN the Euphrates river, halfway between Deir...\n",
       "1    Never have America and its allies had such a h...\n",
       "2    But like their Parthian forebears, Iran and it...\n",
       "3    Iran's gains are even more striking elsewhere....\n",
       "4    Farther south, America's hopes of stemming Ira...\n",
       "Name: Content_Preprocessed, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['Content_Preprocessed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a version of the content where all text inside quotes is replacde by 'Qx'\n",
    "\n",
    "def replace_quotes(X):\n",
    "    \n",
    "    \"\"\"\n",
    "    Replaces all text inside quotes with 'Qx'.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = re.sub(r'\\\"([^\\\"]+?)[^!?\\'\\.,]\\\" ', \"\\'Qx\\' \", X) # \"text\"+space\n",
    "    \n",
    "    X = re.sub(r'\\\"([^\\\"]+?)\\\"\\.', \"\\'Qx\\'.\", X) # \"text\". -- applies to economist (british)\n",
    "    X = re.sub(r'\\\"([^\\\"]+?)\\\",', \"\\'Qx\\',\", X) # \"text\", -- applies to economist (british)\n",
    "    \n",
    "    X = re.sub(r'\\\"([^\\\"]+?),\\\"', \"\\'Qx,\\'\", X) # \"text,\"   \n",
    "    X = re.sub(r'\\\"([^\\\"]+?)[!?\\'\\.]\\\"', \"\\'Qx.\\'\", X) # \"text!\" or \"text?\" or \"text.\" \n",
    "\n",
    "    X = re.sub(r'\\x93(.+?),\\x94', \"\\'Qx,\\'\", X) # \"text,\" -- applies to wired (weird chars)\n",
    "    X = re.sub(r'\\x93(.+?)[! ?\\'\\.]\\x94', \"\\'Qx.\\'\", X) # \"text!\" or \"text \" or \"text?\" or \"text.\" -- wired\n",
    "    X = re.sub(r'\\x93(.+?)\\x94', \"\\'Qx\\'\", X) # \"text\" -- applies to wired (weird chars)\n",
    "    \n",
    "    return X\n",
    "\n",
    "replaced_text = [replace_quotes(s) for s in final_df['Content_Preprocessed'].values]\n",
    "\n",
    "final_df['Content_NoQuotes'] = replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out paragraphs with 20 non-quote words or less\n",
    "\n",
    "final_df_filtered = final_df[final_df['Content_NoQuotes'].apply(lambda x: len([w for w in x.split() if 'Qx' not in w])) > 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bool = final_df['Content_NoQuotes'].apply(lambda x: len([w for w in x.split() if 'Qx' not in w])) > 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_filtered = final_df[['source', 'Content_Preprocessed', 'Content_NoQuotes']][filter_bool.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52922, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content_Preprocessed</th>\n",
       "      <th>Content_NoQuotes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>economist</th>\n",
       "      <td>10982</td>\n",
       "      <td>10982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ew</th>\n",
       "      <td>12414</td>\n",
       "      <td>12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newyorker</th>\n",
       "      <td>15780</td>\n",
       "      <td>15780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wired</th>\n",
       "      <td>13746</td>\n",
       "      <td>13746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Content_Preprocessed  Content_NoQuotes\n",
       "source                                           \n",
       "economist                 10982             10982\n",
       "ew                        12414             12414\n",
       "newyorker                 15780             15780\n",
       "wired                     13746             13746"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check class balance\n",
    "\n",
    "final_df_filtered.groupby('source').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat.textstat import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readability scores\n",
    "# final_df_filtered['readability_f'] = final_df_filtered['Content_Preprocessed'].apply(textstat.flesch_reading_ease)\n",
    "final_df_filtered['readability_SMOG']=final_df_filtered['Content_Preprocessed'].apply(textstat.smog_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize by sentences\n",
    "final_df_filtered['Sentence_Tokens'] = final_df_filtered['Content_Preprocessed'].apply(nltk.sent_tokenize)\n",
    "\n",
    "# Number of sentences = length of sentence tokens list\n",
    "final_df_filtered['Num_Sentences'] = final_df_filtered['Sentence_Tokens'].apply(len)\n",
    "\n",
    "# Average sentence length = number of words/number of sentences\n",
    "word_counts = final_df_filtered['Content_Preprocessed'].apply(lambda x: len(x.split()))\n",
    "final_df_filtered['avg_sent_len'] = word_counts/final_df_filtered['Num_Sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_filtered.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>Content_Preprocessed</th>\n",
       "      <th>Content_NoQuotes</th>\n",
       "      <th>readability_f</th>\n",
       "      <th>readability_SMOG</th>\n",
       "      <th>Sentence_Tokens</th>\n",
       "      <th>Num_Sentences</th>\n",
       "      <th>avg_sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19466</th>\n",
       "      <td>21553</td>\n",
       "      <td>wired</td>\n",
       "      <td>WIRED: Peter Thiel, expressing his dissatisfac...</td>\n",
       "      <td>WIRED: Peter Thiel, expressing his dissatisfac...</td>\n",
       "      <td>65.93</td>\n",
       "      <td>10.6</td>\n",
       "      <td>[WIRED: Peter Thiel, expressing his dissatisfa...</td>\n",
       "      <td>38</td>\n",
       "      <td>13.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18804</th>\n",
       "      <td>20796</td>\n",
       "      <td>wired</td>\n",
       "      <td>WIRED: You founded Metafilter, a communal webl...</td>\n",
       "      <td>WIRED: You founded Metafilter, a communal webl...</td>\n",
       "      <td>74.39</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[WIRED: You founded Metafilter, a communal web...</td>\n",
       "      <td>37</td>\n",
       "      <td>13.027027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38487</th>\n",
       "      <td>44973</td>\n",
       "      <td>newyorker</td>\n",
       "      <td>In a conversation that took place in a buildin...</td>\n",
       "      <td>In a conversation that took place in a buildin...</td>\n",
       "      <td>35.64</td>\n",
       "      <td>10.7</td>\n",
       "      <td>[In a conversation that took place in a buildi...</td>\n",
       "      <td>36</td>\n",
       "      <td>3.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40890</th>\n",
       "      <td>47907</td>\n",
       "      <td>ew</td>\n",
       "      <td>YOU KNOW IT'S BEEN A GOOD PARTY WHEN JOSS WHED...</td>\n",
       "      <td>YOU KNOW IT'S BEEN A GOOD PARTY WHEN JOSS WHED...</td>\n",
       "      <td>69.31</td>\n",
       "      <td>10.6</td>\n",
       "      <td>[YOU KNOW IT'S BEEN A GOOD PARTY WHEN JOSS WHE...</td>\n",
       "      <td>33</td>\n",
       "      <td>16.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15423</th>\n",
       "      <td>16615</td>\n",
       "      <td>wired</td>\n",
       "      <td>GEORGE CARLIN. Lenny Bruce. That dog puppet. W...</td>\n",
       "      <td>GEORGE CARLIN. Lenny Bruce. That dog puppet. W...</td>\n",
       "      <td>65.93</td>\n",
       "      <td>10.3</td>\n",
       "      <td>[GEORGE CARLIN., Lenny Bruce., That dog puppet...</td>\n",
       "      <td>31</td>\n",
       "      <td>12.451613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     source                               Content_Preprocessed  \\\n",
       "19466  21553      wired  WIRED: Peter Thiel, expressing his dissatisfac...   \n",
       "18804  20796      wired  WIRED: You founded Metafilter, a communal webl...   \n",
       "38487  44973  newyorker  In a conversation that took place in a buildin...   \n",
       "40890  47907         ew  YOU KNOW IT'S BEEN A GOOD PARTY WHEN JOSS WHED...   \n",
       "15423  16615      wired  GEORGE CARLIN. Lenny Bruce. That dog puppet. W...   \n",
       "\n",
       "                                        Content_NoQuotes  readability_f  \\\n",
       "19466  WIRED: Peter Thiel, expressing his dissatisfac...          65.93   \n",
       "18804  WIRED: You founded Metafilter, a communal webl...          74.39   \n",
       "38487  In a conversation that took place in a buildin...          35.64   \n",
       "40890  YOU KNOW IT'S BEEN A GOOD PARTY WHEN JOSS WHED...          69.31   \n",
       "15423  GEORGE CARLIN. Lenny Bruce. That dog puppet. W...          65.93   \n",
       "\n",
       "       readability_SMOG                                    Sentence_Tokens  \\\n",
       "19466              10.6  [WIRED: Peter Thiel, expressing his dissatisfa...   \n",
       "18804               9.0  [WIRED: You founded Metafilter, a communal web...   \n",
       "38487              10.7  [In a conversation that took place in a buildi...   \n",
       "40890              10.6  [YOU KNOW IT'S BEEN A GOOD PARTY WHEN JOSS WHE...   \n",
       "15423              10.3  [GEORGE CARLIN., Lenny Bruce., That dog puppet...   \n",
       "\n",
       "       Num_Sentences  avg_sent_len  \n",
       "19466             38     13.421053  \n",
       "18804             37     13.027027  \n",
       "38487             36      3.416667  \n",
       "40890             33     16.515152  \n",
       "15423             31     12.451613  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_filtered.sort_values(by = 'Num_Sentences', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    52922.000000\n",
       "mean         4.949851\n",
       "std          2.728297\n",
       "min          1.000000\n",
       "25%          3.000000\n",
       "50%          5.000000\n",
       "75%          6.000000\n",
       "max         38.000000\n",
       "Name: Num_Sentences, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_filtered.Num_Sentences.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    52922.000000\n",
       "mean        20.051542\n",
       "std          7.261307\n",
       "min          3.000000\n",
       "25%         15.285714\n",
       "50%         19.000000\n",
       "75%         23.500000\n",
       "max        180.000000\n",
       "Name: avg_sent_len, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_filtered.avg_sent_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get standard deviation sentence length for each paragraph\n",
    "\n",
    "def getSDSentLen(p):\n",
    "    sent_tokens = p[0]\n",
    "    avg_sent_len = p[1]\n",
    "    \n",
    "    # Get length of each sentence as np array\n",
    "    lengths = np.array([len(s.split()) for s in sent_tokens])\n",
    "    \n",
    "    # Calculate SD\n",
    "    return (np.sqrt(np.sum((lengths - avg_sent_len)**2)/len(sent_tokens)))\n",
    "\n",
    "final_df_filtered['sd_sent_len'] = final_df_filtered[['Sentence_Tokens',\n",
    "                                                      'avg_sent_len']].apply(lambda x: getSDSentLen(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If have time: These functions could be rewritten so they run faster...\n",
    "\n",
    "def normStopWordFrequency(para):\n",
    "    stopwords1=set(stopwords.words('english'))\n",
    "    word_tok = nltk.word_tokenize(para) #need to take out commas plus other stuff\n",
    "    NoWord = [',','(',')',':',';','.','%','\\x96','\\x94','{','}','[',']','!','?',\"''\",\"``\", 'Qx']\n",
    "    word_tok2 = [i for i in word_tok if i not in NoWord]\n",
    "    nw = len(word_tok2)\n",
    "    word_tok_stop=[i for i in word_tok if i.lower() in stopwords1]\n",
    "    n_stop=len(word_tok_stop)\n",
    "    return(n_stop/nw)\n",
    "\n",
    "def normFunctWordFrequency(functional,para):\n",
    "    word_tok = nltk.word_tokenize(para) #need to take out commas plus other stuff\n",
    "    NoWord = [',','(',')',':',';','.','%','\\x96','\\x94','{','}','[',']','!','?',\"''\",\"``\", 'Qx']\n",
    "    word_tok2 = [i for i in word_tok if i not in NoWord]\n",
    "    nw = len(word_tok2)\n",
    "    word_tok_funct=[i for i in word_tok if i.lower() in functional]\n",
    "    n_funct=len(word_tok_funct)\n",
    "    return(n_funct/nw)\n",
    "\n",
    "def normPunctFrequency(para):\n",
    "    count = lambda l1, l2: len(list(filter(lambda c: c in l2, l1)))\n",
    "                               \n",
    "    no_punct = count(para, string.punctuation)\n",
    "    word_tok = nltk.word_tokenize(para) #need to take out commas plus other stuff\n",
    "    NoWord = [',','(',')',':',';','.','%','\\x96','\\x94','{','}','[',']','!','?',\"''\",\"``\", 'Qx']\n",
    "    word_tok2 = [i for i in word_tok if i not in NoWord]\n",
    "    nw = len(word_tok2)\n",
    "    return(no_punct/nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_filtered['norm_stop_freq'] = final_df_filtered.apply(lambda row: normStopWordFrequency(row['Content_NoQuotes']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_filtered['norm_punct_freq'] = final_df_filtered.apply(lambda row: normPunctFrequency(row['Content_NoQuotes']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get functional words\n",
    "\n",
    "functional_file = open(\"functional.txt\", \"r\")\n",
    "f_words = [word.strip() for line in functional_file.readlines() for word in line.split(',') if word.strip()]\n",
    "functional_file.close()\n",
    "\n",
    "functional = list(set(f_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_filtered['norm_funct_freq'] = final_df_filtered.apply(lambda row: normFunctWordFrequency(functional,\n",
    "                                                                                                  row['Content_NoQuotes']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Dataframe for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>Content_Preprocessed</th>\n",
       "      <th>Content_NoQuotes</th>\n",
       "      <th>readability_f</th>\n",
       "      <th>readability_SMOG</th>\n",
       "      <th>Sentence_Tokens</th>\n",
       "      <th>Num_Sentences</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>sd_sent_len</th>\n",
       "      <th>norm_stop_freq</th>\n",
       "      <th>norm_punct_freq</th>\n",
       "      <th>norm_funct_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>economist</td>\n",
       "      <td>DOWN the Euphrates river, halfway between Deir...</td>\n",
       "      <td>DOWN the Euphrates river, halfway between Deir...</td>\n",
       "      <td>50.46</td>\n",
       "      <td>11.2</td>\n",
       "      <td>[DOWN the Euphrates river, halfway between Dei...</td>\n",
       "      <td>3</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>11.841546</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>economist</td>\n",
       "      <td>Never have America and its allies had such a h...</td>\n",
       "      <td>Never have America and its allies had such a h...</td>\n",
       "      <td>62.68</td>\n",
       "      <td>10.7</td>\n",
       "      <td>[Never have America and its allies had such a ...</td>\n",
       "      <td>4</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.391165</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>economist</td>\n",
       "      <td>But like their Parthian forebears, Iran and it...</td>\n",
       "      <td>But like their Parthian forebears, Iran and it...</td>\n",
       "      <td>91.31</td>\n",
       "      <td>5.7</td>\n",
       "      <td>[But like their Parthian forebears, Iran and i...</td>\n",
       "      <td>5</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>5.844656</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.436620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>economist</td>\n",
       "      <td>Iran's gains are even more striking elsewhere....</td>\n",
       "      <td>Iran's gains are even more striking elsewhere....</td>\n",
       "      <td>61.87</td>\n",
       "      <td>11.6</td>\n",
       "      <td>[Iran's gains are even more striking elsewhere...</td>\n",
       "      <td>5</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>7.626270</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>economist</td>\n",
       "      <td>Farther south, America's hopes of stemming Ira...</td>\n",
       "      <td>Farther south, America's hopes of stemming Ira...</td>\n",
       "      <td>52.49</td>\n",
       "      <td>13.6</td>\n",
       "      <td>[Farther south, America's hopes of stemming Ir...</td>\n",
       "      <td>3</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>7.408704</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     source                               Content_Preprocessed  \\\n",
       "0      0  economist  DOWN the Euphrates river, halfway between Deir...   \n",
       "1      1  economist  Never have America and its allies had such a h...   \n",
       "2      2  economist  But like their Parthian forebears, Iran and it...   \n",
       "3      3  economist  Iran's gains are even more striking elsewhere....   \n",
       "4      4  economist  Farther south, America's hopes of stemming Ira...   \n",
       "\n",
       "                                    Content_NoQuotes  readability_f  \\\n",
       "0  DOWN the Euphrates river, halfway between Deir...          50.46   \n",
       "1  Never have America and its allies had such a h...          62.68   \n",
       "2  But like their Parthian forebears, Iran and it...          91.31   \n",
       "3  Iran's gains are even more striking elsewhere....          61.87   \n",
       "4  Farther south, America's hopes of stemming Ira...          52.49   \n",
       "\n",
       "   readability_SMOG                                    Sentence_Tokens  \\\n",
       "0              11.2  [DOWN the Euphrates river, halfway between Dei...   \n",
       "1              10.7  [Never have America and its allies had such a ...   \n",
       "2               5.7  [But like their Parthian forebears, Iran and i...   \n",
       "3              11.6  [Iran's gains are even more striking elsewhere...   \n",
       "4              13.6  [Farther south, America's hopes of stemming Ir...   \n",
       "\n",
       "   Num_Sentences  avg_sent_len  sd_sent_len  norm_stop_freq  norm_punct_freq  \\\n",
       "0              3     20.666667    11.841546        0.421875         0.234375   \n",
       "1              4     17.000000     3.391165        0.500000         0.132353   \n",
       "2              5     13.800000     5.844656        0.422535         0.197183   \n",
       "3              5     17.800000     7.626270        0.422222         0.255556   \n",
       "4              3     18.666667     7.408704        0.350000         0.316667   \n",
       "\n",
       "   norm_funct_freq  \n",
       "0         0.390625  \n",
       "1         0.470588  \n",
       "2         0.436620  \n",
       "3         0.411111  \n",
       "4         0.333333  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = final_df_filtered[['source','readability_SMOG','avg_sent_len', 'Num_Sentences',\n",
    "                                 'sd_sent_len','norm_stop_freq','norm_punct_freq','norm_funct_freq']]\n",
    "\n",
    "# NOTE: Descriptive statistics for SMOG show more variation than Flesch, so dropped Flesch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>readability_SMOG</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>Num_Sentences</th>\n",
       "      <th>sd_sent_len</th>\n",
       "      <th>norm_stop_freq</th>\n",
       "      <th>norm_punct_freq</th>\n",
       "      <th>norm_funct_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>economist</td>\n",
       "      <td>11.2</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>11.841546</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>economist</td>\n",
       "      <td>10.7</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.391165</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economist</td>\n",
       "      <td>5.7</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>5.844656</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.436620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>economist</td>\n",
       "      <td>11.6</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>7.626270</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economist</td>\n",
       "      <td>13.6</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>7.408704</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  readability_SMOG  avg_sent_len  Num_Sentences  sd_sent_len  \\\n",
       "0  economist              11.2     20.666667              3    11.841546   \n",
       "1  economist              10.7     17.000000              4     3.391165   \n",
       "2  economist               5.7     13.800000              5     5.844656   \n",
       "3  economist              11.6     17.800000              5     7.626270   \n",
       "4  economist              13.6     18.666667              3     7.408704   \n",
       "\n",
       "   norm_stop_freq  norm_punct_freq  norm_funct_freq  \n",
       "0        0.421875         0.234375         0.390625  \n",
       "1        0.500000         0.132353         0.470588  \n",
       "2        0.422535         0.197183         0.436620  \n",
       "3        0.422222         0.255556         0.411111  \n",
       "4        0.350000         0.316667         0.333333  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle for modeling\n",
    "\n",
    "with open('pickles/features_04_29.pkl', 'wb') as f:\n",
    "    pickle.dump(df_features, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SVM ... (move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X -> features, y -> label\n",
    "X=df_features[['readability_f','readability_SMOG','avg_sent_len','sd_sent_len','norm_stop_freq','norm_punct_freq','norm_funct_freq']]\n",
    "y=df_features.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing X, y into train and test data \n",
    "#We use stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
    "svm_predictions = svm_model_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49770107703\n"
     ]
    }
   ],
   "source": [
    "accuracy = svm_model_linear.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1475  258  760  802]\n",
      " [ 236 1437 1245  806]\n",
      " [ 517  436 3357  424]\n",
      " [ 946  696  849 1633]]\n"
     ]
    }
   ],
   "source": [
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, svm_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_model_radial = SVC(kernel = 'rbf', C = 1).fit(X_train, y_train)\n",
    "svm_predictions = svm_model_radial.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = svm_model_radial.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
