{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled dataframe\n",
    "\n",
    "file = 'pickles/features_04_29.pkl'\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    df_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>readability_SMOG</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>Num_Sentences</th>\n",
       "      <th>sd_sent_len</th>\n",
       "      <th>norm_stop_freq</th>\n",
       "      <th>norm_punct_freq</th>\n",
       "      <th>norm_funct_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>economist</td>\n",
       "      <td>11.2</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>11.841546</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>economist</td>\n",
       "      <td>10.7</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.391165</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economist</td>\n",
       "      <td>5.7</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>5.844656</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.436620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>economist</td>\n",
       "      <td>11.6</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>7.626270</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economist</td>\n",
       "      <td>13.6</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>7.408704</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  readability_SMOG  avg_sent_len  Num_Sentences  sd_sent_len  \\\n",
       "0  economist              11.2     20.666667              3    11.841546   \n",
       "1  economist              10.7     17.000000              4     3.391165   \n",
       "2  economist               5.7     13.800000              5     5.844656   \n",
       "3  economist              11.6     17.800000              5     7.626270   \n",
       "4  economist              13.6     18.666667              3     7.408704   \n",
       "\n",
       "   norm_stop_freq  norm_punct_freq  norm_funct_freq  \n",
       "0        0.421875         0.234375         0.390625  \n",
       "1        0.500000         0.132353         0.470588  \n",
       "2        0.422535         0.197183         0.436620  \n",
       "3        0.422222         0.255556         0.411111  \n",
       "4        0.350000         0.316667         0.333333  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A bunch of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score,f1_score,precision_score,recall_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(multi_class='multinomial',solver='lbfgs')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('XGBoost',XGBClassifier()))\n",
    "#models.append(('SVM', SVC(kernel = 'linear')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52922\n"
     ]
    }
   ],
   "source": [
    "# X -> features, y -> label\n",
    "X=df_features[['readability_SMOG','avg_sent_len','sd_sent_len','norm_stop_freq','norm_punct_freq','norm_funct_freq']]\n",
    "y=df_features.source\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Testing\n",
      "LR\n",
      "Training\n",
      "Testing\n",
      "LDA\n",
      "Training\n",
      "Testing\n",
      "KNN\n",
      "Training\n",
      "Testing\n",
      "CART\n",
      "Training\n",
      "Testing\n",
      "NB\n",
      "Training\n",
      "Testing\n",
      "XGBoost\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.3, random_state = 0)\n",
    "\n",
    "val_accuracy_all={}\n",
    "val_fscore_all={}\n",
    "val_precision_all={}\n",
    "val_recall_all={}\n",
    "\n",
    "train_accuracy_all={}\n",
    "train_fscore_all={}\n",
    "train_precision_all={}\n",
    "train_recall_all={}\n",
    "\n",
    "for name,model in models:\n",
    "    print('Training')\n",
    "    clf=model.fit(X_train,y_train)\n",
    "    print('Testing')\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(name)\n",
    "    val_precision_all[name]=precision_score(y_test,y_pred,average='macro')\n",
    "    val_recall_all[name]=recall_score(y_test,y_pred,average='macro')\n",
    "    val_fscore_all[name]=f1_score(y_test, y_pred, average='macro')\n",
    "    val_accuracy_all[name]=accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred=clf.predict(X_train)\n",
    "    train_precision_all[name]=precision_score(y_train,y_train_pred,average='macro')\n",
    "    train_recall_all[name]=recall_score(y_train,y_train_pred,average='macro')\n",
    "    train_fscore_all[name]=f1_score(y_train,y_train_pred, average='macro')\n",
    "    train_accuracy_all[name]=accuracy_score(y_train,y_train_pred)\n",
    "\n",
    "val_classifier_results=pd.DataFrame({'Accuracy':pd.Series(val_accuracy_all),'Precision':pd.Series(val_precision_all),'Recall':pd.Series(val_recall_all),'F1_Score':pd.Series(val_fscore_all)}) \n",
    "\n",
    "train_classifier_results=pd.DataFrame({'Accuracy':pd.Series(train_accuracy_all),'Precision':pd.Series(train_precision_all),'Recall':pd.Series(train_recall_all),'F1_Score':pd.Series(train_fscore_all)})  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Accuracy  F1_Score  Precision    Recall\n",
      "CART     0.998380  0.998357   0.998293  0.998425\n",
      "KNN      0.558753  0.553917   0.562523  0.564764\n",
      "LDA      0.502470  0.488085   0.497672  0.490090\n",
      "LR       0.476097  0.463192   0.470995  0.462512\n",
      "NB       0.456256  0.442735   0.457185  0.461091\n",
      "XGBoost  0.535025  0.524606   0.529712  0.524329\n"
     ]
    }
   ],
   "source": [
    "print(train_classifier_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Accuracy  F1_Score  Precision    Recall\n",
      "CART     0.407886  0.402823   0.403393  0.402669\n",
      "KNN      0.359829  0.353328   0.354126  0.363224\n",
      "LDA      0.505007  0.489856   0.497572  0.491886\n",
      "LR       0.481262  0.467167   0.475677  0.466879\n",
      "NB       0.463816  0.451440   0.464418  0.468654\n",
      "XGBoost  0.526800  0.515957   0.520347  0.515760\n"
     ]
    }
   ],
   "source": [
    "print(val_classifier_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search. Needs to be completed\n",
    "X_train_XG, X_test_XG, \\\n",
    "y_train_XG, y_test_XG = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Param grid to optimize across\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'n_estimators': [100,200,300,500,1000,1500,2000]\n",
    "        }\n",
    "\n",
    "# stratified k fold object\n",
    "skf = model_selection.StratifiedKFold(n_splits=2, shuffle = True, random_state = 1001)\n",
    "\n",
    "# instantiate\n",
    "xgb = xgboost.XGBClassifier()\n",
    "\n",
    "# optimized to f1\n",
    "grid_search = GridSearchCV(xgb,\n",
    "                           param_grid=params,\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=4,\n",
    "                           cv=skf.split(X,y),\n",
    "                           verbose=3,\n",
    "                           refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=<generator object _BaseKFold.split at 0x0000021F1C434F10>,\n",
      "       error_score='raise',\n",
      "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1),\n",
      "       fit_params=None, iid=True, n_jobs=4,\n",
      "       param_grid={'min_child_weight': [1, 5, 10], 'gamma': [0.5, 1, 1.5, 2, 5], 'subsample': [0.6, 0.8, 1.0], 'colsample_bytree': [0.6, 0.8, 1.0], 'max_depth': [3, 4, 5], 'learning_rate': [0.05, 0.1, 0.2], 'n_estimators': [100, 200, 300, 500, 1000, 1500, 2000]},\n",
      "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
      "       scoring='accuracy', verbose=3)\n"
     ]
    }
   ],
   "source": [
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid search:\n",
    "\n",
    "# vary kernels\n",
    "# vary 'C'\n",
    "\n",
    "# Record testing error AND training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM with grid search. Needs to be completed\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['accuracy','precision_macro', 'recall_macro','f1_macro']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try different regularization techniques\n",
    "\n",
    "# If it's not overfitting, maybe try adding in some interaction terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
